<!doctype html><html class=no-js lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>使用tensorflow和OpenCV合并人眼 - 火龙果的博客</title><script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script><meta name=description content><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-124887845-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script data-ad-client=ca-pub-4136853851848129 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body class=body><div class="container container--outer"><header class=header><div class=container><div class=logo><a class=logo__link href=/ title=火龙果的博客 rel=home><div class=logo__title>火龙果的博客</div><div class=logo__tagline>🥳No Code no Bugs</div></a></div><div class=divider></div></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>使用tensorflow和OpenCV合并人眼</h1></header><div class="content post__content clearfix"><p>在很多时候对摄影师而言，合影一直是摄影师之痛。很多时候的场景是，都站好了，拍完一看有人闭眼了，这个时候是再拍一张还是就这样呢？？</p><p>如题，我们要合并人眼，听起来很神奇的一个事情，目的是在合影时进行连拍，然后利用tensorflow训练的模型替换掉闭眼的哥们，最终达到所有人睁眼的效果。</p><p>目标是开发一个计算机视觉程序，检测眼睛是打开还是关闭的状态。</p><p>源码已上传到<a href=https://github.com/heyanlong/mix-face>GitHub仓库</a></p><p>搞起～</p><h2 id=第一阶段>第一阶段</h2><p>首选需要训练一个cnn，这里需要使用tensorflow和keras库，先安装他们</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell>pip install tensorflow
pip install keras
</code></pre></div><p>开始准备一些睁眼闭眼的图片，并将图片裁剪为24 x 24 大小，准好好数据之后，开始训练一个具备睁眼闭眼检测的二元分类器。</p><p>睁眼闭眼图片可以在我仓库的dataset文件夹中找到。</p><p>编辑train.py 引入所需的库</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> keras.models <span style=color:#f92672>import</span> Sequential
<span style=color:#f92672>from</span> keras.layers <span style=color:#f92672>import</span> Conv2D
<span style=color:#f92672>from</span> keras.layers <span style=color:#f92672>import</span> AveragePooling2D
<span style=color:#f92672>from</span> keras.layers <span style=color:#f92672>import</span> Flatten
<span style=color:#f92672>from</span> keras.layers <span style=color:#f92672>import</span> Dense
<span style=color:#f92672>from</span> keras.preprocessing.image <span style=color:#f92672>import</span> ImageDataGenerator
</code></pre></div><p>然后加载数据集</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>collect</span>():
	train_datagen <span style=color:#f92672>=</span> ImageDataGenerator(
			rescale<span style=color:#f92672>=</span><span style=color:#ae81ff>1.</span><span style=color:#f92672>/</span><span style=color:#ae81ff>255</span>,
			shear_range<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>,
			horizontal_flip<span style=color:#f92672>=</span>True, 
		)

	val_datagen <span style=color:#f92672>=</span> ImageDataGenerator(
			rescale<span style=color:#f92672>=</span><span style=color:#ae81ff>1.</span><span style=color:#f92672>/</span><span style=color:#ae81ff>255</span>,
			shear_range<span style=color:#f92672>=</span><span style=color:#ae81ff>0.2</span>,
			horizontal_flip<span style=color:#f92672>=</span>True,		)

	train_generator <span style=color:#f92672>=</span> train_datagen<span style=color:#f92672>.</span>flow_from_directory(
	    directory<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;dataset/train&#34;</span>,
	    target_size<span style=color:#f92672>=</span>(IMG_SIZE, IMG_SIZE),
	    color_mode<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;grayscale&#34;</span>,
	    batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>,
	    class_mode<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;binary&#34;</span>,
	    shuffle<span style=color:#f92672>=</span>True,
	    seed<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>
	)

	val_generator <span style=color:#f92672>=</span> val_datagen<span style=color:#f92672>.</span>flow_from_directory(
	    directory<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;dataset/val&#34;</span>,
	    target_size<span style=color:#f92672>=</span>(IMG_SIZE, IMG_SIZE),
	    color_mode<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;grayscale&#34;</span>,
	    batch_size<span style=color:#f92672>=</span><span style=color:#ae81ff>32</span>,
	    class_mode<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;binary&#34;</span>,
	    shuffle<span style=color:#f92672>=</span>True,
	    seed<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>
	)
	<span style=color:#66d9ef>return</span> train_generator, val_generator
</code></pre></div><p>制作模型</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>train</span>(train_generator, val_generator):
	STEP_SIZE_TRAIN<span style=color:#f92672>=</span>train_generator<span style=color:#f92672>.</span>n<span style=color:#f92672>//</span>train_generator<span style=color:#f92672>.</span>batch_size
	STEP_SIZE_VALID<span style=color:#f92672>=</span>val_generator<span style=color:#f92672>.</span>n<span style=color:#f92672>//</span>val_generator<span style=color:#f92672>.</span>batch_size

	<span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#39;[LOG] Intialize Neural Network&#39;</span>)
	
	model <span style=color:#f92672>=</span> Sequential()

	model<span style=color:#f92672>.</span>add(Conv2D(filters<span style=color:#f92672>=</span><span style=color:#ae81ff>6</span>, kernel_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>, input_shape<span style=color:#f92672>=</span>(IMG_SIZE,IMG_SIZE,<span style=color:#ae81ff>1</span>)))
	model<span style=color:#f92672>.</span>add(AveragePooling2D())

	model<span style=color:#f92672>.</span>add(Conv2D(filters<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>, kernel_size<span style=color:#f92672>=</span>(<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>3</span>), activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>))
	model<span style=color:#f92672>.</span>add(AveragePooling2D())

	model<span style=color:#f92672>.</span>add(Flatten())

	model<span style=color:#f92672>.</span>add(Dense(units<span style=color:#f92672>=</span><span style=color:#ae81ff>120</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>))

	model<span style=color:#f92672>.</span>add(Dense(units<span style=color:#f92672>=</span><span style=color:#ae81ff>84</span>, activation<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;relu&#39;</span>))

	model<span style=color:#f92672>.</span>add(Dense(units<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>, activation <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;sigmoid&#39;</span>))


	model<span style=color:#f92672>.</span>compile(loss<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;binary_crossentropy&#39;</span>, optimizer<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;adam&#39;</span>, metrics<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#39;accuracy&#39;</span>])

	model<span style=color:#f92672>.</span>fit_generator(generator<span style=color:#f92672>=</span>train_generator,
	                    steps_per_epoch<span style=color:#f92672>=</span>STEP_SIZE_TRAIN,
	                    validation_data<span style=color:#f92672>=</span>val_generator,
	                    validation_steps<span style=color:#f92672>=</span>STEP_SIZE_VALID,
	                    epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>20</span>
	)
	save_model(model)
</code></pre></div><p>ok，现在已经拥有了简单的cnn，并且具备睁眼闭眼识别能力。</p><h2 id=第二阶段>第二阶段</h2><p>程序处理思路</p><ol><li>识别出第一张照片所有人脸位置</li><li>对同一个位置的人脸，对每一张图片相同位置进行扣图，得到一个人多张人脸</li><li>对每一个人的多张人脸进行眼睛打开关闭评分</li><li>得分最高的人脸替换掉第一张图片同样位置的人脸</li></ol><p>传入多张照片，并在第一张照片中识别所有人脸，然后根据第一张人脸坐标扣出同一个人的其他人脸</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>upload</span>():
    images <span style=color:#f92672>=</span> request<span style=color:#f92672>.</span>files<span style=color:#f92672>.</span>getlist(<span style=color:#e6db74>&#39;img[]&#39;</span>)  <span style=color:#75715e># a upload files</span>
    <span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#34;******&#34;</span>, images)

    <span style=color:#66d9ef>if</span> len(images):
        im <span style=color:#f92672>=</span> []
        <span style=color:#75715e># save</span>
        <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(len(images)):
            image <span style=color:#f92672>=</span> images[i]
            input <span style=color:#f92672>=</span> config<span style=color:#f92672>.</span>upload_dir <span style=color:#f92672>+</span> image<span style=color:#f92672>.</span>filename

            im<span style=color:#f92672>.</span>append({
                <span style=color:#e6db74>&#39;raw&#39;</span>: image,
                <span style=color:#e6db74>&#39;path&#39;</span>: input,
            })

            <span style=color:#66d9ef>try</span>:
                image<span style=color:#f92672>.</span>save(input)
            <span style=color:#66d9ef>except</span> <span style=color:#a6e22e>Exception</span> <span style=color:#66d9ef>as</span> e:
                <span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#34;Error: &#34;</span>, e)

        <span style=color:#75715e># read first image as base image</span>
        first_image_path <span style=color:#f92672>=</span> im[<span style=color:#ae81ff>0</span>][<span style=color:#e6db74>&#39;path&#39;</span>]
        first_image <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>imread(first_image_path)

        gray <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>cvtColor(first_image, cv2<span style=color:#f92672>.</span>COLOR_RGB2GRAY)

        faces <span style=color:#f92672>=</span> face_cascade<span style=color:#f92672>.</span>detectMultiScale(gray)

        <span style=color:#75715e># save first image faces rect</span>
        im[<span style=color:#ae81ff>0</span>][<span style=color:#e6db74>&#39;faces&#39;</span>] <span style=color:#f92672>=</span> faces

        mini_face <span style=color:#f92672>=</span> []
        <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(len(faces)):
            mini_face<span style=color:#f92672>.</span>append({
                <span style=color:#e6db74>&#39;ok&#39;</span>: {},
                <span style=color:#e6db74>&#39;face_list&#39;</span>: []
            })

        <span style=color:#66d9ef>for</span> j <span style=color:#f92672>in</span> range(len(im)):
            img <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>imread(im[j][<span style=color:#e6db74>&#39;path&#39;</span>])
            <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(len(faces)):
                face <span style=color:#f92672>=</span> faces[i]
                rect <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>rint([face[<span style=color:#ae81ff>0</span>], face[<span style=color:#ae81ff>1</span>], face[<span style=color:#ae81ff>0</span>] <span style=color:#f92672>+</span> face[<span style=color:#ae81ff>2</span>], face[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>+</span> face[<span style=color:#ae81ff>3</span>]])
                rect <span style=color:#f92672>=</span> rect<span style=color:#f92672>.</span>astype(int)
                f <span style=color:#f92672>=</span> img[rect[<span style=color:#ae81ff>1</span>]:rect[<span style=color:#ae81ff>3</span>], rect[<span style=color:#ae81ff>0</span>]:rect[<span style=color:#ae81ff>2</span>]]
                mini_face[i][<span style=color:#e6db74>&#39;face_list&#39;</span>]<span style=color:#f92672>.</span>append({
                    <span style=color:#e6db74>&#39;image&#39;</span>: f,
                    <span style=color:#e6db74>&#39;rect&#39;</span>: face,
                    <span style=color:#e6db74>&#39;np_rect&#39;</span>: rect
                })

        <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(len(mini_face)):
            faces <span style=color:#f92672>=</span> mini_face[i][<span style=color:#e6db74>&#39;face_list&#39;</span>]
            <span style=color:#66d9ef>for</span> j <span style=color:#f92672>in</span> range(len(faces)):
                face <span style=color:#f92672>=</span> faces[j]
                max_face_image <span style=color:#f92672>=</span> tool<span style=color:#f92672>.</span>img_resize_to_target_white(face[<span style=color:#e6db74>&#39;image&#39;</span>])
                left_eye <span style=color:#f92672>=</span> right_eye <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
                prediction <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>

                <span style=color:#75715e># detect eyes</span>
                eyes <span style=color:#f92672>=</span> cropEyes(max_face_image)
                <span style=color:#66d9ef>if</span> eyes <span style=color:#f92672>is</span> None:
                    <span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#34;eyes is null&#34;</span>)
                <span style=color:#66d9ef>else</span>:
                    left_eye, right_eye <span style=color:#f92672>=</span> eyes
                    prediction <span style=color:#f92672>=</span> (model<span style=color:#f92672>.</span>predict(cnnPreprocess(left_eye)) <span style=color:#f92672>+</span> model<span style=color:#f92672>.</span>predict(
                        cnnPreprocess(right_eye))) <span style=color:#f92672>/</span> <span style=color:#ae81ff>2.0</span>

                mini_face[i][<span style=color:#e6db74>&#39;face_list&#39;</span>][j][<span style=color:#e6db74>&#39;prediction&#39;</span>] <span style=color:#f92672>=</span> prediction

                <span style=color:#66d9ef>if</span> <span style=color:#e6db74>&#39;prediction&#39;</span> <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> mini_face[i][<span style=color:#e6db74>&#39;ok&#39;</span>]:
                    mini_face[i][<span style=color:#e6db74>&#39;ok&#39;</span>][<span style=color:#e6db74>&#39;face&#39;</span>] <span style=color:#f92672>=</span> face
                    mini_face[i][<span style=color:#e6db74>&#39;ok&#39;</span>][<span style=color:#e6db74>&#39;prediction&#39;</span>] <span style=color:#f92672>=</span> prediction
                <span style=color:#66d9ef>else</span>:
                    <span style=color:#66d9ef>if</span> mini_face[i][<span style=color:#e6db74>&#39;ok&#39;</span>][<span style=color:#e6db74>&#39;prediction&#39;</span>] <span style=color:#f92672>&lt;</span> prediction:
                        mini_face[i][<span style=color:#e6db74>&#39;ok&#39;</span>][<span style=color:#e6db74>&#39;face&#39;</span>] <span style=color:#f92672>=</span> face
                        mini_face[i][<span style=color:#e6db74>&#39;ok&#39;</span>][<span style=color:#e6db74>&#39;prediction&#39;</span>] <span style=color:#f92672>=</span> prediction

        <span style=color:#75715e># merge</span>
        <span style=color:#66d9ef>for</span> item <span style=color:#f92672>in</span> mini_face:
            ok <span style=color:#f92672>=</span> item[<span style=color:#e6db74>&#39;ok&#39;</span>]
            <span style=color:#66d9ef>print</span>(ok[<span style=color:#e6db74>&#39;prediction&#39;</span>])
            first_image <span style=color:#f92672>=</span> merge_image(first_image, ok[<span style=color:#e6db74>&#39;face&#39;</span>][<span style=color:#e6db74>&#39;image&#39;</span>], ok[<span style=color:#e6db74>&#39;face&#39;</span>][<span style=color:#e6db74>&#39;rect&#39;</span>])

        cv2<span style=color:#f92672>.</span>putText(first_image, <span style=color:#e6db74>&#39;mix@magvii &#39;</span> <span style=color:#f92672>+</span> time<span style=color:#f92672>.</span>strftime(<span style=color:#e6db74>&#39;%Y-%m-</span><span style=color:#e6db74>%d</span><span style=color:#e6db74> %H:%M:%S&#39;</span>, time<span style=color:#f92672>.</span>localtime(time<span style=color:#f92672>.</span>time())), (<span style=color:#ae81ff>150</span>, <span style=color:#ae81ff>150</span>), cv2<span style=color:#f92672>.</span>FONT_HERSHEY_SIMPLEX, <span style=color:#ae81ff>5</span>, (<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0</span>), <span style=color:#ae81ff>5</span>, cv2<span style=color:#f92672>.</span>LINE_AA)
        cv2<span style=color:#f92672>.</span>imwrite(<span style=color:#e6db74>&#34;mix/dist/img/merged_image.jpg&#34;</span>, first_image)
        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#39;{&#34;code&#34;: 1000}&#39;</span>
    <span style=color:#66d9ef>else</span>:
        <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#39;{&#34;code&#34;: 9999}&#39;</span>
</code></pre></div><p>由于剪裁出的人脸过小，进行人脸组评分的时候识别器识别失败，我们进行人脸放大，得到比当前人脸大两倍的图像</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>img_resize_to_target_white</span>(input_image):
    img <span style=color:#f92672>=</span> input_image
    h <span style=color:#f92672>=</span> img<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>0</span>]
    w <span style=color:#f92672>=</span> img<span style=color:#f92672>.</span>shape[<span style=color:#ae81ff>1</span>]
    target <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>ones((<span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> h, <span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> w), dtype<span style=color:#f92672>=</span>np<span style=color:#f92672>.</span>uint8) <span style=color:#f92672>*</span> <span style=color:#ae81ff>255</span>

    half_h <span style=color:#f92672>=</span> int(h <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span>)
    half_w <span style=color:#f92672>=</span> int(w <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span>)
    ret <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>cvtColor(target, cv2<span style=color:#f92672>.</span>COLOR_GRAY2BGR)
    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> h):
        <span style=color:#66d9ef>for</span> j <span style=color:#f92672>in</span> range(<span style=color:#ae81ff>2</span> <span style=color:#f92672>*</span> w):
            <span style=color:#66d9ef>if</span> (half_h <span style=color:#f92672>&lt;</span> i) <span style=color:#f92672>and</span> (i <span style=color:#f92672>&lt;</span> h <span style=color:#f92672>+</span> half_h) <span style=color:#f92672>and</span> (half_w <span style=color:#f92672>&lt;</span> j) <span style=color:#f92672>and</span> (j <span style=color:#f92672>&lt;</span> w <span style=color:#f92672>+</span> half_w):
                ret[i, j, <span style=color:#ae81ff>0</span>] <span style=color:#f92672>=</span> img[i <span style=color:#f92672>-</span> half_h, j <span style=color:#f92672>-</span> half_w, <span style=color:#ae81ff>0</span>]
                ret[i, j, <span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> img[i <span style=color:#f92672>-</span> half_h, j <span style=color:#f92672>-</span> half_w, <span style=color:#ae81ff>1</span>]
                ret[i, j, <span style=color:#ae81ff>2</span>] <span style=color:#f92672>=</span> img[i <span style=color:#f92672>-</span> half_h, j <span style=color:#f92672>-</span> half_w, <span style=color:#ae81ff>2</span>]
            <span style=color:#66d9ef>else</span>:
                ret[i, j, <span style=color:#ae81ff>0</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>255</span>
                ret[i, j, <span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>255</span>
                ret[i, j, <span style=color:#ae81ff>2</span>] <span style=color:#f92672>=</span> <span style=color:#ae81ff>255</span>

    <span style=color:#66d9ef>return</span> ret
</code></pre></div><p>根据放大的图像找到左眼和右眼，并处理成24 x 24的图片</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>cropEyes</span>(frame):
    gray <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>cvtColor(frame, cv2<span style=color:#f92672>.</span>COLOR_BGR2GRAY)

    <span style=color:#75715e># detect the face at grayscale image</span>
    te <span style=color:#f92672>=</span> detect(gray)

    <span style=color:#66d9ef>if</span> len(te) <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>:
        <span style=color:#66d9ef>return</span> None
    <span style=color:#66d9ef>elif</span> len(te) <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>1</span>:
        face <span style=color:#f92672>=</span> te[<span style=color:#ae81ff>0</span>]
    <span style=color:#66d9ef>elif</span> len(te) <span style=color:#f92672>==</span> <span style=color:#ae81ff>1</span>:
        [face] <span style=color:#f92672>=</span> te

    <span style=color:#75715e># keep the face region from the whole frame</span>
    face_rect <span style=color:#f92672>=</span> dlib<span style=color:#f92672>.</span>rectangle(left<span style=color:#f92672>=</span>int(face[<span style=color:#ae81ff>0</span>]), top<span style=color:#f92672>=</span>int(face[<span style=color:#ae81ff>1</span>]),
                               right<span style=color:#f92672>=</span>int(face[<span style=color:#ae81ff>2</span>]), bottom<span style=color:#f92672>=</span>int(face[<span style=color:#ae81ff>3</span>]))
    <span style=color:#75715e># determine the facial landmarks for the face region</span>
    shape <span style=color:#f92672>=</span> predictor(gray, face_rect)
    shape <span style=color:#f92672>=</span> face_utils<span style=color:#f92672>.</span>shape_to_np(shape)

    (rStart, rEnd) <span style=color:#f92672>=</span> face_utils<span style=color:#f92672>.</span>FACIAL_LANDMARKS_IDXS[<span style=color:#e6db74>&#34;left_eye&#34;</span>]
    (lStart, lEnd) <span style=color:#f92672>=</span> face_utils<span style=color:#f92672>.</span>FACIAL_LANDMARKS_IDXS[<span style=color:#e6db74>&#34;right_eye&#34;</span>]

    <span style=color:#75715e># extract the left and right eye coordinates</span>
    leftEye <span style=color:#f92672>=</span> shape[lStart:lEnd]
    rightEye <span style=color:#f92672>=</span> shape[rStart:rEnd]

    l_uppery <span style=color:#f92672>=</span> min(leftEye[<span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>1</span>])
    l_lowy <span style=color:#f92672>=</span> max(leftEye[<span style=color:#ae81ff>4</span>:, <span style=color:#ae81ff>1</span>])
    minxl <span style=color:#f92672>=</span> leftEye[<span style=color:#ae81ff>0</span>][<span style=color:#ae81ff>0</span>]
    maxxl <span style=color:#f92672>=</span> leftEye[<span style=color:#ae81ff>3</span>][<span style=color:#ae81ff>0</span>]
    higl <span style=color:#f92672>=</span> (maxxl <span style=color:#f92672>-</span> minxl) <span style=color:#f92672>/</span> (<span style=color:#ae81ff>24</span> <span style=color:#f92672>/</span> <span style=color:#ae81ff>24</span>)
    minyl <span style=color:#f92672>=</span> l_uppery <span style=color:#f92672>+</span> (((l_lowy <span style=color:#f92672>-</span> l_uppery) <span style=color:#f92672>-</span> higl) <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span>)
    maxyl <span style=color:#f92672>=</span> minyl <span style=color:#f92672>+</span> higl

    <span style=color:#75715e># crop the eye rectangle from the frame</span>
    left_eye_rect <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>rint([minxl, minyl, maxxl, maxyl])
    left_eye_rect <span style=color:#f92672>=</span> left_eye_rect<span style=color:#f92672>.</span>astype(int)
    left_eye_image <span style=color:#f92672>=</span> gray[(left_eye_rect[<span style=color:#ae81ff>1</span>]):left_eye_rect[<span style=color:#ae81ff>3</span>], (left_eye_rect[<span style=color:#ae81ff>0</span>]):left_eye_rect[<span style=color:#ae81ff>2</span>]]

    <span style=color:#75715e># same as left eye at right eye</span>
    r_uppery <span style=color:#f92672>=</span> min(rightEye[<span style=color:#ae81ff>1</span>:<span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>1</span>])
    r_lowy <span style=color:#f92672>=</span> max(rightEye[<span style=color:#ae81ff>4</span>:, <span style=color:#ae81ff>1</span>])
    minxr <span style=color:#f92672>=</span> rightEye[<span style=color:#ae81ff>0</span>][<span style=color:#ae81ff>0</span>]
    maxxr <span style=color:#f92672>=</span> rightEye[<span style=color:#ae81ff>3</span>][<span style=color:#ae81ff>0</span>]
    higr <span style=color:#f92672>=</span> (maxxr <span style=color:#f92672>-</span> minxr) <span style=color:#f92672>/</span> (<span style=color:#ae81ff>24</span> <span style=color:#f92672>/</span> <span style=color:#ae81ff>24</span>)
    minyr <span style=color:#f92672>=</span> r_uppery <span style=color:#f92672>+</span> (((r_lowy <span style=color:#f92672>-</span> r_uppery) <span style=color:#f92672>-</span> higr) <span style=color:#f92672>/</span> <span style=color:#ae81ff>2</span>)
    maxyr <span style=color:#f92672>=</span> minyr <span style=color:#f92672>+</span> higr

    right_eye_rect <span style=color:#f92672>=</span> np<span style=color:#f92672>.</span>rint([minxr, minyr, maxxr, maxyr])
    right_eye_rect <span style=color:#f92672>=</span> right_eye_rect<span style=color:#f92672>.</span>astype(int)
    right_eye_image <span style=color:#f92672>=</span> gray[right_eye_rect[<span style=color:#ae81ff>1</span>]:right_eye_rect[<span style=color:#ae81ff>3</span>], right_eye_rect[<span style=color:#ae81ff>0</span>]:right_eye_rect[<span style=color:#ae81ff>2</span>]]

    <span style=color:#75715e># if it doesn&#39;t detect left or right eye return None</span>
    <span style=color:#66d9ef>if</span> <span style=color:#ae81ff>0</span> <span style=color:#f92672>in</span> left_eye_image<span style=color:#f92672>.</span>shape <span style=color:#f92672>or</span> <span style=color:#ae81ff>0</span> <span style=color:#f92672>in</span> right_eye_image<span style=color:#f92672>.</span>shape:
        <span style=color:#66d9ef>return</span> None
    <span style=color:#75715e># resize for the conv net</span>
    left_eye_image <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>resize(left_eye_image, (<span style=color:#ae81ff>24</span>, <span style=color:#ae81ff>24</span>))
    right_eye_image <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>resize(right_eye_image, (<span style=color:#ae81ff>24</span>, <span style=color:#ae81ff>24</span>))
    right_eye_image <span style=color:#f92672>=</span> cv2<span style=color:#f92672>.</span>flip(right_eye_image, <span style=color:#ae81ff>1</span>)
    <span style=color:#75715e># return left and right eye</span>
    <span style=color:#66d9ef>return</span> left_eye_image, right_eye_image
</code></pre></div><p>进行人眼评分，分值在0到1直接，0代表绝对闭眼，1代表绝对睁眼</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>prediction <span style=color:#f92672>=</span> (model<span style=color:#f92672>.</span>predict(cnnPreprocess(left_eye)) <span style=color:#f92672>+</span> model<span style=color:#f92672>.</span>predict(
                        cnnPreprocess(right_eye))) <span style=color:#f92672>/</span> <span style=color:#ae81ff>2.0</span>
</code></pre></div><p>最佳人脸与第一张人脸合并</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>merge_image</span>(lack_face_img, face_img, rect):
    (x, y, w, h) <span style=color:#f92672>=</span> rect
    <span style=color:#75715e>#x += 10</span>
    <span style=color:#75715e>#y += 10</span>
    height, width, _ <span style=color:#f92672>=</span> face_img<span style=color:#f92672>.</span>shape
    <span style=color:#66d9ef>for</span> i <span style=color:#f92672>in</span> range(height):
        <span style=color:#66d9ef>for</span> j <span style=color:#f92672>in</span> range(width):
            lack_face_img[i <span style=color:#f92672>+</span> y, j <span style=color:#f92672>+</span> x, <span style=color:#ae81ff>0</span>] <span style=color:#f92672>=</span> face_img[i, j, <span style=color:#ae81ff>0</span>]
            lack_face_img[i <span style=color:#f92672>+</span> y, j <span style=color:#f92672>+</span> x, <span style=color:#ae81ff>1</span>] <span style=color:#f92672>=</span> face_img[i, j, <span style=color:#ae81ff>1</span>]
            lack_face_img[i <span style=color:#f92672>+</span> y, j <span style=color:#f92672>+</span> x, <span style=color:#ae81ff>2</span>] <span style=color:#f92672>=</span> face_img[i, j, <span style=color:#ae81ff>2</span>]
    <span style=color:#66d9ef>return</span> lack_face_img
</code></pre></div><p>到此为止，我们就把多张质量不一的照片合并成一张质量最好的照片了～</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/macos/ rel=tag>MacOS</a></li><li class=tags__item><a class="tags__link btn" href=/tags/opencv/ rel=tag>OpenCV</a></li><li class=tags__item><a class="tags__link btn" href=/tags/python/ rel=tag>Python</a></li><li class=tags__item><a class="tags__link btn" href=/tags/tensorflow/ rel=tag>tensorflow</a></li></ul></div></footer></article></main><div class="authorbox clearfix"><figure class=authorbox__avatar><img alt="Yanlong avatar" src=/img/avatar.jpeg class=avatar height=90 width=90></figure><div class=authorbox__header><span class=authorbox__name>关于 Yanlong</span></div><div class=authorbox__description>程序员 / Apache Committer / PECL成员</div></div></div><aside class=sidebar><div class="widget-search widget"><form class=widget-search__form role=search method=get action=https://google.com/search><label><input class=widget-search__field type=search placeholder=搜索... name=q aria-label=搜索...></label>
<input class=widget-search__submit type=submit value=Search>
<input type=hidden name=sitesearch value=https://yanlong.me/></form></div><div class="widget-recent widget"><h4 class=widget__title>近期文章</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=/post/ffmpeg-gpu/>编译并使用GPU加速的ffmpeg</a></li><li class=widget__item><a class=widget__link href=/post/deploy-blog-use-github-actions/>使用Github Actions自动编译部署基于hugo的博客</a></li><li class=widget__item><a class=widget__link href=/post/nginx-static-build/>Nginx 静态编译</a></li><li class=widget__item><a class=widget__link href=/post/github-actions/>Github Actions 简介</a></li><li class=widget__item><a class=widget__link href=/post/golang-encrypt-io-copy/>Golang Encrypt Io Copy</a></li><li class=widget__item><a class=widget__link href=/post/mix-eye/>使用tensorflow和OpenCV合并人眼</a></li><li class=widget__item><a class=widget__link href=/post/install-dlib-on-macos/>在MacOS上安装Dlib</a></li><li class=widget__item><a class=widget__link href=/post/install-opencv-on-macos/>在MacOS上安装OpenCV</a></li><li class=widget__item><a class=widget__link href=/post/delete-team-viewer-in-full/>彻底删除Mac上的TeamViewer</a></li><li class=widget__item><a class=widget__link href=/post/docker-multi-stage-build/>Docker 多阶段构建</a></li></ul></div></div><div class="widget-taglist widget"><h4 class=widget__title>标签</h4><div class=widget__content><a class="widget-taglist__link widget__link btn" href=/tags/docker/ title=docker>docker</a>
<a class="widget-taglist__link widget__link btn" href=/tags/ffmpeg/ title=ffmpeg>ffmpeg</a>
<a class="widget-taglist__link widget__link btn" href=/tags/github/ title=github>github</a>
<a class="widget-taglist__link widget__link btn" href=/tags/golang/ title=golang>golang</a>
<a class="widget-taglist__link widget__link btn" href=/tags/macos/ title=MacOS>MacOS</a>
<a class="widget-taglist__link widget__link btn" href=/tags/nginx/ title=nginx>nginx</a>
<a class="widget-taglist__link widget__link btn" href=/tags/nvidia/ title=nvidia>nvidia</a>
<a class="widget-taglist__link widget__link btn" href=/tags/opencv/ title=OpenCV>OpenCV</a>
<a class="widget-taglist__link widget__link btn" href=/tags/php/ title=PHP>PHP</a>
<a class="widget-taglist__link widget__link btn" href=/tags/python/ title=Python>Python</a>
<a class="widget-taglist__link widget__link btn" href=/tags/tensorflow/ title=tensorflow>tensorflow</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E6%9C%BA%E6%A2%B0%E9%94%AE%E7%9B%98/ title=机械键盘>机械键盘</a></div></div><div class="widget-social widget"><h4 class="widget-social__title widget__title">社交</h4><div class="widget-social__content widget__content"><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Twitter rel="noopener noreferrer" href=https://twitter.com/YanlongHe target=_blank><svg class="widget-social__link-icon icon icon-twitter" width="24" height="24" viewBox="0 0 384 312"><path d="m384 36.9c-14.1 6.3-29.3 10.5-45.2 12.4 16.3-9.7 28.8-25.2 34.6-43.6-15.2 9-32.1 15.6-50 19.1-14.4-15.2-34.9-24.8-57.5-24.8-43.5.0-78.8 35.3-78.8 78.8.0 6.2.7 12.2 2 17.9-65.5-3.3-123.5-34.6-162.4-82.3-6.7 11.6-10.6 25.2-10.6 39.6.0 27.3 13.9 51.4 35 65.6-12.9-.4-25.1-4-35.7-9.9v1c0 38.2 27.2 70 63.2 77.2-6.6 1.8-13.6 2.8-20.8 2.8-5.1.0-10-.5-14.8-1.4 10 31.3 39.1 54.1 73.6 54.7-27 21.1-60.9 33.7-97.8 33.7-6.4.0-12.6-.4-18.8-1.1 34.9 22.4 76.3 35.4 120.8 35.4 144.9.0 224.1-120 224.1-224.1.0-3.4-.1-6.8-.2-10.2 15.4-11.1 28.7-25 39.3-40.8z"/></svg><span>Twitter</span></a></div><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=GitHub rel="noopener noreferrer" href=https://github.com/heyanlong target=_blank><svg class="widget-social__link-icon icon icon-github" width="24" height="24" viewBox="0 0 384 374"><path d="m192 0C85.9.0.0 85.8.0 191.7c0 84.7 55 156.6 131.3 181.9 9.6 1.8 13.1-4.2 13.1-9.2.0-4.6-.2-16.6-.3-32.6-53.4 11.6-64.7-25.7-64.7-25.7-8.7-22.1-21.3-28-21.3-28-17.4-11.9 1.3-11.6 1.3-11.6 19.3 1.4 29.4 19.8 29.4 19.8 17.1 29.3 44.9 20.8 55.9 15.9 1.7-12.4 6.7-20.8 12.2-25.6-42.6-4.8-87.5-21.3-87.5-94.8.0-20.9 7.5-38 19.8-51.4-2-4.9-8.6-24.3 1.9-50.7.0.0 16.1-5.2 52.8 19.7 15.3-4.2 31.7-6.4 48.1-6.5 16.3.1 32.7 2.2 48.1 6.5 36.7-24.8 52.8-19.7 52.8-19.7 10.5 26.4 3.9 45.9 1.9 50.7 12.3 13.4 19.7 30.5 19.7 51.4.0 73.7-44.9 89.9-87.7 94.6 6.9 5.9 13 17.6 13 35.5.0 25.6-.2 46.3-.2 52.6.0 5.1 3.5 11.1 13.2 9.2 76.2-25.5 131.2-97.3 131.2-182 0-105.9-86-191.7-192-191.7z"/></svg><span>GitHub</span></a></div><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Email href=mailto:yanlong.hee@gmail.com><svg class="widget-social__link-icon icon icon-mail" width="24" height="24" viewBox="0 0 416 288"><path d="m0 16v256 16h16 384 16v-16V16 0h-16H16 0zm347 16-139 92.5L69 32zM199 157.5l9 5.5 9-5.5L384 46v210H32V46z"/></svg><span>yanlong.hee@gmail.com</span></a></div></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__links><a class=footer__link href=https://zzrdark.github.io/ target=_blank>zzrdark的技术专栏</a> | <a class=footer__link href=http://www.is17.com/ target=_blank>依十七</a> | <a class=footer__link href=https://wujunze.com/ target=_blank>吴钧泽博客</a> | <a class=footer__link href=https://yuerblog.cc/ target=_blank>鱼儿的博客</a></div><div class=footer__copyright>&copy; 2020 yanlong.me.
<span class=footer__copyright-credits>基于 <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> 引擎和 <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a>主題</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>