<!doctype html><html class=no-js lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>ä½¿ç”¨tensorflowå’ŒOpenCVåˆå¹¶äººçœ¼ - ç«é¾™æœçš„åšå®¢</title><script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script><meta name=description content><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=/css/style.css><link rel="shortcut icon" href=/favicon.ico><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-124887845-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script data-ad-client=ca-pub-4136853851848129 async src=https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js></script></head><body class=body><div class="container container--outer"><header class=header><div class=container><div class=logo><a class=logo__link href=/ title=ç«é¾™æœçš„åšå®¢ rel=home><div class=logo__title>ç«é¾™æœçš„åšå®¢</div><div class=logo__tagline>ğŸ¥³No Code no Bugs</div></a></div><div class=divider></div></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>ä½¿ç”¨tensorflowå’ŒOpenCVåˆå¹¶äººçœ¼</h1></header><div class="content post__content clearfix"><p>åœ¨å¾ˆå¤šæ—¶å€™å¯¹æ‘„å½±å¸ˆè€Œè¨€ï¼Œåˆå½±ä¸€ç›´æ˜¯æ‘„å½±å¸ˆä¹‹ç—›ã€‚å¾ˆå¤šæ—¶å€™çš„åœºæ™¯æ˜¯ï¼Œéƒ½ç«™å¥½äº†ï¼Œæ‹å®Œä¸€çœ‹æœ‰äººé—­çœ¼äº†ï¼Œè¿™ä¸ªæ—¶å€™æ˜¯å†æ‹ä¸€å¼ è¿˜æ˜¯å°±è¿™æ ·å‘¢ï¼Ÿï¼Ÿ</p><p>å¦‚é¢˜ï¼Œæˆ‘ä»¬è¦åˆå¹¶äººçœ¼ï¼Œå¬èµ·æ¥å¾ˆç¥å¥‡çš„ä¸€ä¸ªäº‹æƒ…ï¼Œç›®çš„æ˜¯åœ¨åˆå½±æ—¶è¿›è¡Œè¿æ‹ï¼Œç„¶ååˆ©ç”¨tensorflowè®­ç»ƒçš„æ¨¡å‹æ›¿æ¢æ‰é—­çœ¼çš„å“¥ä»¬ï¼Œæœ€ç»ˆè¾¾åˆ°æ‰€æœ‰äººççœ¼çš„æ•ˆæœã€‚</p><p>ç›®æ ‡æ˜¯å¼€å‘ä¸€ä¸ªè®¡ç®—æœºè§†è§‰ç¨‹åºï¼Œæ£€æµ‹çœ¼ç›æ˜¯æ‰“å¼€è¿˜æ˜¯å…³é—­çš„çŠ¶æ€ã€‚</p><p>æºç å·²ä¸Šä¼ åˆ°<a href=https://github.com/heyanlong/mix-face>GitHubä»“åº“</a></p><p>æèµ·ï½</p><h2 id=ç¬¬ä¸€é˜¶æ®µ>ç¬¬ä¸€é˜¶æ®µ</h2><p>é¦–é€‰éœ€è¦è®­ç»ƒä¸€ä¸ªcnnï¼Œè¿™é‡Œéœ€è¦ä½¿ç”¨tensorflowå’Œkerasåº“ï¼Œå…ˆå®‰è£…ä»–ä»¬</p><pre><code class=language-shell>pip install tensorflow
pip install keras
</code></pre><p>å¼€å§‹å‡†å¤‡ä¸€äº›ççœ¼é—­çœ¼çš„å›¾ç‰‡ï¼Œå¹¶å°†å›¾ç‰‡è£å‰ªä¸º24 x 24 å¤§å°ï¼Œå‡†å¥½å¥½æ•°æ®ä¹‹åï¼Œå¼€å§‹è®­ç»ƒä¸€ä¸ªå…·å¤‡ççœ¼é—­çœ¼æ£€æµ‹çš„äºŒå…ƒåˆ†ç±»å™¨ã€‚</p><p>ççœ¼é—­çœ¼å›¾ç‰‡å¯ä»¥åœ¨æˆ‘ä»“åº“çš„datasetæ–‡ä»¶å¤¹ä¸­æ‰¾åˆ°ã€‚</p><p>ç¼–è¾‘train.py å¼•å…¥æ‰€éœ€çš„åº“</p><pre><code class=language-python>from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import AveragePooling2D
from keras.layers import Flatten
from keras.layers import Dense
from keras.preprocessing.image import ImageDataGenerator
</code></pre><p>ç„¶ååŠ è½½æ•°æ®é›†</p><pre><code class=language-python>def collect():
	train_datagen = ImageDataGenerator(
			rescale=1./255,
			shear_range=0.2,
			horizontal_flip=True, 
		)

	val_datagen = ImageDataGenerator(
			rescale=1./255,
			shear_range=0.2,
			horizontal_flip=True,		)

	train_generator = train_datagen.flow_from_directory(
	    directory=&quot;dataset/train&quot;,
	    target_size=(IMG_SIZE, IMG_SIZE),
	    color_mode=&quot;grayscale&quot;,
	    batch_size=32,
	    class_mode=&quot;binary&quot;,
	    shuffle=True,
	    seed=42
	)

	val_generator = val_datagen.flow_from_directory(
	    directory=&quot;dataset/val&quot;,
	    target_size=(IMG_SIZE, IMG_SIZE),
	    color_mode=&quot;grayscale&quot;,
	    batch_size=32,
	    class_mode=&quot;binary&quot;,
	    shuffle=True,
	    seed=42
	)
	return train_generator, val_generator
</code></pre><p>åˆ¶ä½œæ¨¡å‹</p><pre><code class=language-python>def train(train_generator, val_generator):
	STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size
	STEP_SIZE_VALID=val_generator.n//val_generator.batch_size

	print('[LOG] Intialize Neural Network')
	
	model = Sequential()

	model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(IMG_SIZE,IMG_SIZE,1)))
	model.add(AveragePooling2D())

	model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))
	model.add(AveragePooling2D())

	model.add(Flatten())

	model.add(Dense(units=120, activation='relu'))

	model.add(Dense(units=84, activation='relu'))

	model.add(Dense(units=1, activation = 'sigmoid'))


	model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

	model.fit_generator(generator=train_generator,
	                    steps_per_epoch=STEP_SIZE_TRAIN,
	                    validation_data=val_generator,
	                    validation_steps=STEP_SIZE_VALID,
	                    epochs=20
	)
	save_model(model)
</code></pre><p>okï¼Œç°åœ¨å·²ç»æ‹¥æœ‰äº†ç®€å•çš„cnnï¼Œå¹¶ä¸”å…·å¤‡ççœ¼é—­çœ¼è¯†åˆ«èƒ½åŠ›ã€‚</p><h2 id=ç¬¬äºŒé˜¶æ®µ>ç¬¬äºŒé˜¶æ®µ</h2><p>ç¨‹åºå¤„ç†æ€è·¯</p><ol><li>è¯†åˆ«å‡ºç¬¬ä¸€å¼ ç…§ç‰‡æ‰€æœ‰äººè„¸ä½ç½®</li><li>å¯¹åŒä¸€ä¸ªä½ç½®çš„äººè„¸ï¼Œå¯¹æ¯ä¸€å¼ å›¾ç‰‡ç›¸åŒä½ç½®è¿›è¡Œæ‰£å›¾ï¼Œå¾—åˆ°ä¸€ä¸ªäººå¤šå¼ äººè„¸</li><li>å¯¹æ¯ä¸€ä¸ªäººçš„å¤šå¼ äººè„¸è¿›è¡Œçœ¼ç›æ‰“å¼€å…³é—­è¯„åˆ†</li><li>å¾—åˆ†æœ€é«˜çš„äººè„¸æ›¿æ¢æ‰ç¬¬ä¸€å¼ å›¾ç‰‡åŒæ ·ä½ç½®çš„äººè„¸</li></ol><p>ä¼ å…¥å¤šå¼ ç…§ç‰‡ï¼Œå¹¶åœ¨ç¬¬ä¸€å¼ ç…§ç‰‡ä¸­è¯†åˆ«æ‰€æœ‰äººè„¸ï¼Œç„¶åæ ¹æ®ç¬¬ä¸€å¼ äººè„¸åæ ‡æ‰£å‡ºåŒä¸€ä¸ªäººçš„å…¶ä»–äººè„¸</p><pre><code class=language-python>def upload():
    images = request.files.getlist('img[]')  # a upload files
    print(&quot;******&quot;, images)

    if len(images):
        im = []
        # save
        for i in range(len(images)):
            image = images[i]
            input = config.upload_dir + image.filename

            im.append({
                'raw': image,
                'path': input,
            })

            try:
                image.save(input)
            except Exception as e:
                print(&quot;Error: &quot;, e)

        # read first image as base image
        first_image_path = im[0]['path']
        first_image = cv2.imread(first_image_path)

        gray = cv2.cvtColor(first_image, cv2.COLOR_RGB2GRAY)

        faces = face_cascade.detectMultiScale(gray)

        # save first image faces rect
        im[0]['faces'] = faces

        mini_face = []
        for i in range(len(faces)):
            mini_face.append({
                'ok': {},
                'face_list': []
            })

        for j in range(len(im)):
            img = cv2.imread(im[j]['path'])
            for i in range(len(faces)):
                face = faces[i]
                rect = np.rint([face[0], face[1], face[0] + face[2], face[1] + face[3]])
                rect = rect.astype(int)
                f = img[rect[1]:rect[3], rect[0]:rect[2]]
                mini_face[i]['face_list'].append({
                    'image': f,
                    'rect': face,
                    'np_rect': rect
                })

        for i in range(len(mini_face)):
            faces = mini_face[i]['face_list']
            for j in range(len(faces)):
                face = faces[j]
                max_face_image = tool.img_resize_to_target_white(face['image'])
                left_eye = right_eye = 0
                prediction = 0

                # detect eyes
                eyes = cropEyes(max_face_image)
                if eyes is None:
                    print(&quot;eyes is null&quot;)
                else:
                    left_eye, right_eye = eyes
                    prediction = (model.predict(cnnPreprocess(left_eye)) + model.predict(
                        cnnPreprocess(right_eye))) / 2.0

                mini_face[i]['face_list'][j]['prediction'] = prediction

                if 'prediction' not in mini_face[i]['ok']:
                    mini_face[i]['ok']['face'] = face
                    mini_face[i]['ok']['prediction'] = prediction
                else:
                    if mini_face[i]['ok']['prediction'] &lt; prediction:
                        mini_face[i]['ok']['face'] = face
                        mini_face[i]['ok']['prediction'] = prediction

        # merge
        for item in mini_face:
            ok = item['ok']
            print(ok['prediction'])
            first_image = merge_image(first_image, ok['face']['image'], ok['face']['rect'])

        cv2.putText(first_image, 'mix@magvii ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())), (150, 150), cv2.FONT_HERSHEY_SIMPLEX, 5, (0, 0, 0), 5, cv2.LINE_AA)
        cv2.imwrite(&quot;mix/dist/img/merged_image.jpg&quot;, first_image)
        return '{&quot;code&quot;: 1000}'
    else:
        return '{&quot;code&quot;: 9999}'
</code></pre><p>ç”±äºå‰ªè£å‡ºçš„äººè„¸è¿‡å°ï¼Œè¿›è¡Œäººè„¸ç»„è¯„åˆ†çš„æ—¶å€™è¯†åˆ«å™¨è¯†åˆ«å¤±è´¥ï¼Œæˆ‘ä»¬è¿›è¡Œäººè„¸æ”¾å¤§ï¼Œå¾—åˆ°æ¯”å½“å‰äººè„¸å¤§ä¸¤å€çš„å›¾åƒ</p><pre><code class=language-python>def img_resize_to_target_white(input_image):
    img = input_image
    h = img.shape[0]
    w = img.shape[1]
    target = np.ones((2 * h, 2 * w), dtype=np.uint8) * 255

    half_h = int(h / 2)
    half_w = int(w / 2)
    ret = cv2.cvtColor(target, cv2.COLOR_GRAY2BGR)
    for i in range(2 * h):
        for j in range(2 * w):
            if (half_h &lt; i) and (i &lt; h + half_h) and (half_w &lt; j) and (j &lt; w + half_w):
                ret[i, j, 0] = img[i - half_h, j - half_w, 0]
                ret[i, j, 1] = img[i - half_h, j - half_w, 1]
                ret[i, j, 2] = img[i - half_h, j - half_w, 2]
            else:
                ret[i, j, 0] = 255
                ret[i, j, 1] = 255
                ret[i, j, 2] = 255

    return ret
</code></pre><p>æ ¹æ®æ”¾å¤§çš„å›¾åƒæ‰¾åˆ°å·¦çœ¼å’Œå³çœ¼ï¼Œå¹¶å¤„ç†æˆ24 x 24çš„å›¾ç‰‡</p><pre><code class=language-python>def cropEyes(frame):
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # detect the face at grayscale image
    te = detect(gray)

    if len(te) == 0:
        return None
    elif len(te) &gt; 1:
        face = te[0]
    elif len(te) == 1:
        [face] = te

    # keep the face region from the whole frame
    face_rect = dlib.rectangle(left=int(face[0]), top=int(face[1]),
                               right=int(face[2]), bottom=int(face[3]))
    # determine the facial landmarks for the face region
    shape = predictor(gray, face_rect)
    shape = face_utils.shape_to_np(shape)

    (rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[&quot;left_eye&quot;]
    (lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[&quot;right_eye&quot;]

    # extract the left and right eye coordinates
    leftEye = shape[lStart:lEnd]
    rightEye = shape[rStart:rEnd]

    l_uppery = min(leftEye[1:3, 1])
    l_lowy = max(leftEye[4:, 1])
    minxl = leftEye[0][0]
    maxxl = leftEye[3][0]
    higl = (maxxl - minxl) / (24 / 24)
    minyl = l_uppery + (((l_lowy - l_uppery) - higl) / 2)
    maxyl = minyl + higl

    # crop the eye rectangle from the frame
    left_eye_rect = np.rint([minxl, minyl, maxxl, maxyl])
    left_eye_rect = left_eye_rect.astype(int)
    left_eye_image = gray[(left_eye_rect[1]):left_eye_rect[3], (left_eye_rect[0]):left_eye_rect[2]]

    # same as left eye at right eye
    r_uppery = min(rightEye[1:3, 1])
    r_lowy = max(rightEye[4:, 1])
    minxr = rightEye[0][0]
    maxxr = rightEye[3][0]
    higr = (maxxr - minxr) / (24 / 24)
    minyr = r_uppery + (((r_lowy - r_uppery) - higr) / 2)
    maxyr = minyr + higr

    right_eye_rect = np.rint([minxr, minyr, maxxr, maxyr])
    right_eye_rect = right_eye_rect.astype(int)
    right_eye_image = gray[right_eye_rect[1]:right_eye_rect[3], right_eye_rect[0]:right_eye_rect[2]]

    # if it doesn't detect left or right eye return None
    if 0 in left_eye_image.shape or 0 in right_eye_image.shape:
        return None
    # resize for the conv net
    left_eye_image = cv2.resize(left_eye_image, (24, 24))
    right_eye_image = cv2.resize(right_eye_image, (24, 24))
    right_eye_image = cv2.flip(right_eye_image, 1)
    # return left and right eye
    return left_eye_image, right_eye_image
</code></pre><p>è¿›è¡Œäººçœ¼è¯„åˆ†ï¼Œåˆ†å€¼åœ¨0åˆ°1ç›´æ¥ï¼Œ0ä»£è¡¨ç»å¯¹é—­çœ¼ï¼Œ1ä»£è¡¨ç»å¯¹ççœ¼</p><pre><code class=language-python>prediction = (model.predict(cnnPreprocess(left_eye)) + model.predict(
                        cnnPreprocess(right_eye))) / 2.0
</code></pre><p>æœ€ä½³äººè„¸ä¸ç¬¬ä¸€å¼ äººè„¸åˆå¹¶</p><pre><code class=language-python>def merge_image(lack_face_img, face_img, rect):
    (x, y, w, h) = rect
    #x += 10
    #y += 10
    height, width, _ = face_img.shape
    for i in range(height):
        for j in range(width):
            lack_face_img[i + y, j + x, 0] = face_img[i, j, 0]
            lack_face_img[i + y, j + x, 1] = face_img[i, j, 1]
            lack_face_img[i + y, j + x, 2] = face_img[i, j, 2]
    return lack_face_img
</code></pre><p>åˆ°æ­¤ä¸ºæ­¢ï¼Œæˆ‘ä»¬å°±æŠŠå¤šå¼ è´¨é‡ä¸ä¸€çš„ç…§ç‰‡åˆå¹¶æˆä¸€å¼ è´¨é‡æœ€å¥½çš„ç…§ç‰‡äº†ï½</p></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 1 0 0-6 3 3 0 0 0 0 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=/tags/macos/ rel=tag>MacOS</a></li><li class=tags__item><a class="tags__link btn" href=/tags/opencv/ rel=tag>OpenCV</a></li><li class=tags__item><a class="tags__link btn" href=/tags/python/ rel=tag>Python</a></li><li class=tags__item><a class="tags__link btn" href=/tags/tensorflow/ rel=tag>tensorflow</a></li></ul></div></footer></article></main><div class="authorbox clearfix"><figure class=authorbox__avatar><img alt="Yanlong avatar" src=/img/avatar.jpeg class=avatar height=90 width=90></figure><div class=authorbox__header><span class=authorbox__name>å…³äº Yanlong</span></div><div class=authorbox__description>ç¨‹åºå‘˜ / Apache Committer / PECLæˆå‘˜</div></div></div><aside class=sidebar><div class="widget-search widget"><form class=widget-search__form role=search method=get action=https://google.com/search><label><input class=widget-search__field type=search placeholder=æœç´¢... name=q aria-label=æœç´¢...></label>
<input class=widget-search__submit type=submit value=Search>
<input type=hidden name=sitesearch value=https://yanlong.me/></form></div><div class="widget-recent widget"><h4 class=widget__title>è¿‘æœŸæ–‡ç« </h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=/post/deploy-blog-use-github-actions/>ä½¿ç”¨Github Actionsè‡ªåŠ¨ç¼–è¯‘éƒ¨ç½²åŸºäºhugoçš„åšå®¢</a></li><li class=widget__item><a class=widget__link href=/post/nginx-static-build/>Nginx é™æ€ç¼–è¯‘</a></li><li class=widget__item><a class=widget__link href=/post/github-actions/>Github Actions ç®€ä»‹</a></li><li class=widget__item><a class=widget__link href=/post/golang-encrypt-io-copy/>Golang Encrypt Io Copy</a></li><li class=widget__item><a class=widget__link href=/post/mix-eye/>ä½¿ç”¨tensorflowå’ŒOpenCVåˆå¹¶äººçœ¼</a></li><li class=widget__item><a class=widget__link href=/post/install-dlib-on-macos/>åœ¨MacOSä¸Šå®‰è£…Dlib</a></li><li class=widget__item><a class=widget__link href=/post/install-opencv-on-macos/>åœ¨MacOSä¸Šå®‰è£…OpenCV</a></li><li class=widget__item><a class=widget__link href=/post/delete-team-viewer-in-full/>å½»åº•åˆ é™¤Macä¸Šçš„TeamViewer</a></li><li class=widget__item><a class=widget__link href=/post/docker-multi-stage-build/>Docker å¤šé˜¶æ®µæ„å»º</a></li><li class=widget__item><a class=widget__link href=/post/leave-yuanf/>ç¦»å¼€å¼€å…ƒé‡‘è</a></li></ul></div></div><div class="widget-taglist widget"><h4 class=widget__title>æ ‡ç­¾</h4><div class=widget__content><a class="widget-taglist__link widget__link btn" href=/tags/docker/ title=docker>docker</a>
<a class="widget-taglist__link widget__link btn" href=/tags/github/ title=github>github</a>
<a class="widget-taglist__link widget__link btn" href=/tags/golang/ title=golang>golang</a>
<a class="widget-taglist__link widget__link btn" href=/tags/macos/ title=MacOS>MacOS</a>
<a class="widget-taglist__link widget__link btn" href=/tags/nginx/ title=nginx>nginx</a>
<a class="widget-taglist__link widget__link btn" href=/tags/opencv/ title=OpenCV>OpenCV</a>
<a class="widget-taglist__link widget__link btn" href=/tags/php/ title=PHP>PHP</a>
<a class="widget-taglist__link widget__link btn" href=/tags/python/ title=Python>Python</a>
<a class="widget-taglist__link widget__link btn" href=/tags/tensorflow/ title=tensorflow>tensorflow</a>
<a class="widget-taglist__link widget__link btn" href=/tags/%E6%9C%BA%E6%A2%B0%E9%94%AE%E7%9B%98/ title=æœºæ¢°é”®ç›˜>æœºæ¢°é”®ç›˜</a></div></div><div class="widget-social widget"><h4 class="widget-social__title widget__title">ç¤¾äº¤</h4><div class="widget-social__content widget__content"><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Twitter rel="noopener noreferrer" href=https://twitter.com/YanlongHe target=_blank><svg class="widget-social__link-icon icon icon-twitter" width="24" height="24" viewBox="0 0 384 312"><path d="m384 36.9c-14.1 6.3-29.3 10.5-45.2 12.4 16.3-9.7 28.8-25.2 34.6-43.6-15.2 9-32.1 15.6-50 19.1-14.4-15.2-34.9-24.8-57.5-24.8-43.5.0-78.8 35.3-78.8 78.8.0 6.2.7 12.2 2 17.9-65.5-3.3-123.5-34.6-162.4-82.3-6.7 11.6-10.6 25.2-10.6 39.6.0 27.3 13.9 51.4 35 65.6-12.9-.4-25.1-4-35.7-9.9v1c0 38.2 27.2 70 63.2 77.2-6.6 1.8-13.6 2.8-20.8 2.8-5.1.0-10-.5-14.8-1.4 10 31.3 39.1 54.1 73.6 54.7-27 21.1-60.9 33.7-97.8 33.7-6.4.0-12.6-.4-18.8-1.1 34.9 22.4 76.3 35.4 120.8 35.4 144.9.0 224.1-120 224.1-224.1.0-3.4-.1-6.8-.2-10.2 15.4-11.1 28.7-25 39.3-40.8z"/></svg><span>Twitter</span></a></div><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=GitHub rel="noopener noreferrer" href=https://github.com/heyanlong target=_blank><svg class="widget-social__link-icon icon icon-github" width="24" height="24" viewBox="0 0 384 374"><path d="m192 0C85.9.0.0 85.8.0 191.7c0 84.7 55 156.6 131.3 181.9 9.6 1.8 13.1-4.2 13.1-9.2.0-4.6-.2-16.6-.3-32.6-53.4 11.6-64.7-25.7-64.7-25.7-8.7-22.1-21.3-28-21.3-28-17.4-11.9 1.3-11.6 1.3-11.6 19.3 1.4 29.4 19.8 29.4 19.8 17.1 29.3 44.9 20.8 55.9 15.9 1.7-12.4 6.7-20.8 12.2-25.6-42.6-4.8-87.5-21.3-87.5-94.8.0-20.9 7.5-38 19.8-51.4-2-4.9-8.6-24.3 1.9-50.7.0.0 16.1-5.2 52.8 19.7 15.3-4.2 31.7-6.4 48.1-6.5 16.3.1 32.7 2.2 48.1 6.5 36.7-24.8 52.8-19.7 52.8-19.7 10.5 26.4 3.9 45.9 1.9 50.7 12.3 13.4 19.7 30.5 19.7 51.4.0 73.7-44.9 89.9-87.7 94.6 6.9 5.9 13 17.6 13 35.5.0 25.6-.2 46.3-.2 52.6.0 5.1 3.5 11.1 13.2 9.2 76.2-25.5 131.2-97.3 131.2-182 0-105.9-86-191.7-192-191.7z"/></svg><span>GitHub</span></a></div><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Email href=mailto:yanlong.hee@gmail.com><svg class="widget-social__link-icon icon icon-mail" width="24" height="24" viewBox="0 0 416 288"><path d="m0 16v256 16h16 384 16v-16V16 0h-16H16 0zm347 16-139 92.5L69 32zM199 157.5l9 5.5 9-5.5L384 46v210H32V46z"/></svg><span>yanlong.hee@gmail.com</span></a></div></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__links><a class=footer__link href=https://zzrdark.github.io/ target=_blank>zzrdarkçš„æŠ€æœ¯ä¸“æ </a> | <a class=footer__link href=http://www.is17.com/ target=_blank>ä¾åä¸ƒ</a> | <a class=footer__link href=https://wujunze.com/ target=_blank>å´é’§æ³½åšå®¢</a> | <a class=footer__link href=https://yuerblog.cc/ target=_blank>é±¼å„¿çš„åšå®¢</a></div><div class=footer__copyright>&copy; 2020 yanlong.me.
<span class=footer__copyright-credits>åŸºäº <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> å¼•æ“å’Œ <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a>ä¸»é¡Œ</span></div></div></footer></div><script async defer src=/js/menu.js></script></body></html>